{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIG — edit as needed\n",
    "# ============================================\n",
    "IN_DIR = \"../Datasets/Ingestor\"  # input folder of CSVs\n",
    "COMBINED_OUT = \"../Datasets/XGB_Train/pairs_combined_with_ids.csv\"  # csv or .parquet\n",
    "\n",
    "# Core\n",
    "GLOB_PATTERN = \"*.csv\"\n",
    "RECURSIVE = False\n",
    "ID_COL = None              # e.g., \"id\"; if None, synthetic id \"filename::rowindex\" is created\n",
    "NEG_PER_POS = 9            # 1 positive + 9 negatives per anchor row\n",
    "\n",
    "# Column split options\n",
    "COLUMN_SPLIT_MODE = \"half\"       # \"half\" = split numeric columns into two halves\n",
    "COLUMN_SPLIT_SHUFFLE = False     # shuffle numeric columns before splitting\n",
    "EXPLICIT_COLS_A = []             # optional explicit assignment\n",
    "EXPLICIT_COLS_B = []             # optional explicit assignment\n",
    "\n",
    "# Row cap per CSV\n",
    "ROW_LIMIT = 10_000               # cap each CSV before pairing\n",
    "ROW_LIMIT_MODE = \"head\"          # \"head\" or \"sample\"\n",
    "\n",
    "# Date parsing → Unix timestamp (only for non-numeric cols)\n",
    "DATE_MIN_VALID_FRACTION = 0.50   # convert to date if ≥50% parse successfully\n",
    "NUMERIC_MIN_VALID_FRACTION = 0.98  # if ≥98% values numeric -> treat as numeric (don’t date-convert)\n",
    "UNIX_UNIT = \"s\"                  # \"s\" for seconds (recommended) or \"ms\" for milliseconds\n",
    "\n",
    "# Logging\n",
    "LOG_EVERY_FILES = 10\n",
    "LOG_LEVEL = \"INFO\"\n",
    "LOG_FILE = None\n",
    "\n",
    "# Columns to DROP from the OUTPUT file\n",
    "DROP_FROM_OUTPUT = [\n",
    "    \"num_nan_a\", \"num_nan_b\", \"num_nan_mismatch\",\n",
    "    \"row_idx_A\", \"row_idx_B\", \"label_type\", \"source_file\"\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# IMPLEMENTATION (notebook-friendly)\n",
    "# ============================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def setup_logging(level: str = \"INFO\", logfile: Optional[str] = None):\n",
    "    lvl = getattr(logging, level.upper(), logging.INFO)\n",
    "    fmt = \"%Y-%m-%d %H:%M:%S | %(levelname)-7s | %(message)s\"\n",
    "    handlers = [logging.StreamHandler()]\n",
    "    if logfile:\n",
    "        os.makedirs(os.path.dirname(os.path.abspath(logfile)) or \".\", exist_ok=True)\n",
    "        handlers.append(logging.FileHandler(logfile, mode=\"w\", encoding=\"utf-8\"))\n",
    "    logging.basicConfig(level=lvl, format=fmt, handlers=handlers)\n",
    "\n",
    "\n",
    "# ---------- preprocessing helpers ----------\n",
    "def _clean_numeric_like_text(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Remove common decorators like commas/spaces before numeric coercion.\"\"\"\n",
    "    return (s.astype(str)\n",
    "              .str.replace(\",\", \"\", regex=False)\n",
    "              .str.replace(\" \", \"\", regex=False)\n",
    "              .str.replace(\"\\u00A0\", \"\", regex=False))  # non-breaking space\n",
    "\n",
    "\n",
    "def detect_numeric_columns(df: pd.DataFrame, *, id_col: Optional[str], min_valid_fraction: float) -> List[str]:\n",
    "    \"\"\"\n",
    "    Columns that are already numeric (or safely numeric after cleaning) — we will NEVER date-convert these.\n",
    "    A column is 'numeric' if pd.to_numeric(..., errors='coerce') yields >= min_valid_fraction non-NaN.\n",
    "    \"\"\"\n",
    "    cols = [c for c in df.columns if (id_col is None or c != id_col)]\n",
    "    numeric_cols = []\n",
    "    for c in cols:\n",
    "        s_num = pd.to_numeric(_clean_numeric_like_text(df[c]), errors=\"coerce\")\n",
    "        if s_num.notna().mean() >= min_valid_fraction:\n",
    "            numeric_cols.append(c)\n",
    "    return numeric_cols\n",
    "\n",
    "\n",
    "def datetime_series_to_unix(dt: pd.Series, unit: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert a timezone-aware datetime64[ns] Series to Unix timestamps with NaN for NaT,\n",
    "    without using deprecated .view on Series.\n",
    "    \"\"\"\n",
    "    # ndarray of datetime64[ns]\n",
    "    arr_dt = dt.to_numpy(dtype=\"datetime64[ns]\")\n",
    "    # Mask NaT\n",
    "    mask_nat = np.isnat(arr_dt)\n",
    "    # Convert to int ns (NaT becomes very negative int -> we’ll null it)\n",
    "    arr_ns = arr_dt.astype(\"datetime64[ns]\").astype(\"int64\")\n",
    "    arr_ns = arr_ns.astype(\"float64\")\n",
    "    arr_ns[mask_nat] = np.nan\n",
    "    if unit == \"ms\":\n",
    "        return pd.Series(arr_ns / 1e6, index=dt.index, dtype=\"float64\")\n",
    "    else:  # seconds\n",
    "        return pd.Series(arr_ns / 1e9, index=dt.index, dtype=\"float64\")\n",
    "\n",
    "\n",
    "def convert_only_non_numeric_dates_to_unix(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: Optional[str],\n",
    "    numeric_min_valid_fraction: float,\n",
    "    date_min_valid_fraction: float,\n",
    "    unit: str,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Only columns that are NOT numeric (per numeric_min_valid_fraction) are tested as dates.\n",
    "    If ≥ date_min_valid_fraction parse, convert them to Unix timestamps.\n",
    "    Returns the converted DataFrame and the list of columns converted.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    candidate_cols = [c for c in df.columns if (id_col is None or c != id_col)]\n",
    "\n",
    "    # 1) Find columns that are already numeric enough — skip them\n",
    "    numeric_cols = set(detect_numeric_columns(df, id_col=id_col, min_valid_fraction=numeric_min_valid_fraction))\n",
    "\n",
    "    converted = []\n",
    "    for c in candidate_cols:\n",
    "        if c in numeric_cols:\n",
    "            continue  # already numeric — do not date-convert\n",
    "\n",
    "        # 2) Try parse as datetime (strict parser by default in recent pandas)\n",
    "        dt = pd.to_datetime(df[c], errors=\"coerce\", utc=True)\n",
    "        frac_ok = dt.notna().mean()\n",
    "        if frac_ok >= date_min_valid_fraction:\n",
    "            df[c] = datetime_series_to_unix(dt, unit=unit)\n",
    "            converted.append(c)\n",
    "        # else: leave it as is (likely categorical/text)\n",
    "\n",
    "    return df, converted\n",
    "\n",
    "\n",
    "def as_numeric(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Coerce given columns to numeric using a lenient cleaning pass.\"\"\"\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        out[c] = pd.to_numeric(_clean_numeric_like_text(out[c]), errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def zscore(arr: np.ndarray) -> np.ndarray:\n",
    "    m = np.nanmean(arr, axis=0)\n",
    "    s = np.nanstd(arr, axis=0)\n",
    "    s[s == 0] = np.nan\n",
    "    Z = (arr - m) / s\n",
    "    return np.where(np.isnan(Z), 0.0, Z)\n",
    "\n",
    "\n",
    "def percentile_rank_matrix(arr: np.ndarray) -> np.ndarray:\n",
    "    n, d = arr.shape\n",
    "    out = np.full((n, d), 0.5, dtype=float)\n",
    "    for j in range(d):\n",
    "        col = arr[:, j]\n",
    "        mask = ~np.isnan(col)\n",
    "        if mask.sum() <= 1:\n",
    "            continue\n",
    "        order = np.argsort(col[mask], kind=\"mergesort\")\n",
    "        ranks = np.empty_like(order, dtype=float)\n",
    "        ranks[order] = np.arange(order.size)\n",
    "        pct = ranks / (mask.sum() - 1)\n",
    "        out[mask, j] = pct\n",
    "    return out\n",
    "\n",
    "\n",
    "def safe_ratio(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    den = np.where(np.abs(b) < 1e-12, np.nan, b)\n",
    "    return a / den\n",
    "\n",
    "\n",
    "def pair_features_numeric(a_raw, b_raw, a_z, b_z, a_pct, b_pct) -> dict:\n",
    "    \"\"\"Compute pairwise similarity/difference features for two numeric vectors.\"\"\"\n",
    "    absdiff = np.abs(a_raw - b_raw)\n",
    "    reldiff = np.abs(safe_ratio(a_raw - b_raw, (np.abs(a_raw) + np.abs(b_raw)) / 2 + 1e-12))\n",
    "    zdiff   = np.abs(a_z - b_z)\n",
    "    pcdiff  = np.abs(a_pct - b_pct)\n",
    "\n",
    "    def nanmean(x):\n",
    "        m = np.nanmean(x)\n",
    "        return float(m) if np.isfinite(m) else np.nan\n",
    "    def nansum(x): return float(np.nansum(x))\n",
    "\n",
    "    L1_raw = nansum(absdiff)\n",
    "    L2_raw = float(np.sqrt(np.nansum(absdiff**2)))\n",
    "    L1_z   = nansum(zdiff)\n",
    "    L2_z   = float(np.sqrt(np.nansum(zdiff**2)))\n",
    "    L1_p   = nansum(pcdiff)\n",
    "    L2_p   = float(np.sqrt(np.nansum(pcdiff**2)))\n",
    "\n",
    "    def safe_cos(a, b):\n",
    "        na = np.linalg.norm(a); nb = np.linalg.norm(b)\n",
    "        if na < 1e-12 or nb < 1e-12: return np.nan\n",
    "        return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "    return {\n",
    "        \"absdiff_mean\": nanmean(absdiff),\n",
    "        \"absdiff_median\": float(np.nanmedian(absdiff)),\n",
    "        \"reldiff_mean\": nanmean(reldiff),\n",
    "        \"zdiff_mean\": nanmean(zdiff),\n",
    "        \"pcdiff_mean\": nanmean(pcdiff),\n",
    "        \"L1_raw\": L1_raw, \"L2_raw\": L2_raw,\n",
    "        \"L1_z\": L1_z,     \"L2_z\": L2_z,\n",
    "        \"L1_pct\": L1_p,   \"L2_pct\": L2_p,\n",
    "        # diagnostics (we will DROP them from the final file)\n",
    "        \"num_nan_a\": float(np.isnan(a_raw).sum()),\n",
    "        \"num_nan_b\": float(np.isnan(b_raw).sum()),\n",
    "        \"num_nan_mismatch\": float((np.isnan(a_raw) ^ np.isnan(b_raw)).sum()),\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- column split ----------\n",
    "def split_numeric_columns(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: Optional[str],\n",
    "    mode: str = \"half\",\n",
    "    shuffle: bool = False,\n",
    "    seed: int = 42,\n",
    "    explicit_A: Optional[List[str]] = None,\n",
    "    explicit_B: Optional[List[str]] = None,\n",
    "    min_valid_fraction: float = 0.01,  # keep cols with at least 1% non-NaN after coercion\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Return (cols_A, cols_B) disjoint numeric feature lists.\n",
    "    Drops columns that become all-NaN after numeric coercion.\n",
    "    \"\"\"\n",
    "    all_cols = df.columns.tolist()\n",
    "    feature_cols = [c for c in all_cols if (id_col is None or c != id_col)]\n",
    "\n",
    "    # Coerce and measure coverage\n",
    "    valid_frac = {}\n",
    "    for c in feature_cols:\n",
    "        s = pd.to_numeric(_clean_numeric_like_text(df[c]), errors=\"coerce\")\n",
    "        valid_frac[c] = s.notna().mean()\n",
    "\n",
    "    numeric_ok = [c for c in feature_cols if valid_frac[c] >= min_valid_fraction]\n",
    "\n",
    "    if explicit_A and explicit_B:\n",
    "        missing = [c for c in (explicit_A + explicit_B) if c not in numeric_ok]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Explicit columns not usable (non-numeric or too many NaNs): {missing}\")\n",
    "        overlap = set(explicit_A).intersection(explicit_B)\n",
    "        if overlap:\n",
    "            raise ValueError(f\"Explicit A/B overlap: {overlap}\")\n",
    "        return list(explicit_A), list(explicit_B)\n",
    "\n",
    "    cols = numeric_ok.copy()\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        rng.shuffle(cols)\n",
    "\n",
    "    dropped = [c for c in feature_cols if c not in numeric_ok]\n",
    "    if dropped:\n",
    "        logging.warning(f\"Dropping {len(dropped)} non-usable column(s): {dropped[:10]}{'...' if len(dropped)>10 else ''}\")\n",
    "\n",
    "    mid = len(cols) // 2\n",
    "    cols_A, cols_B = cols[:mid], cols[mid:]\n",
    "    if len(cols_A) == 0 or len(cols_B) == 0:\n",
    "        raise ValueError(\"Column split resulted in an empty side; need at least two usable numeric columns.\")\n",
    "    return cols_A, cols_B\n",
    "\n",
    "\n",
    "# ---------- builders (column-split pairing) ----------\n",
    "def build_pairs_from_single_df_column_split(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: Optional[str],\n",
    "    negatives_per_positive: int,\n",
    "    seed: int,\n",
    "    source_file: str,\n",
    "    column_split_mode: str = \"half\",\n",
    "    column_split_shuffle: bool = False,\n",
    "    explicit_cols_A: Optional[List[str]] = None,\n",
    "    explicit_cols_B: Optional[List[str]] = None,\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    One CSV:\n",
    "    - ensure ID,\n",
    "    - convert ONLY non-numeric, date-like columns to Unix,\n",
    "    - split numeric columns into A/B,\n",
    "    - for each row i: pos = (i,i); negs = (i, j≠i) K times,\n",
    "    - compute features; return X, y, idx.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Ensure ID column\n",
    "    if id_col is None or id_col not in df.columns:\n",
    "        df = df.copy()\n",
    "        df[\"_row_id\"] = np.arange(len(df)).astype(str)\n",
    "        stem = os.path.splitext(os.path.basename(source_file))[0]\n",
    "        df[\"_row_id\"] = stem + \"::\" + df[\"_row_id\"]\n",
    "        id_col_eff = \"_row_id\"\n",
    "        logging.debug(f\"[{source_file}] Synthetic ID '_row_id' created with file prefix\")\n",
    "    else:\n",
    "        id_col_eff = id_col\n",
    "\n",
    "    # 1) Convert ONLY non-numeric, date-like columns to Unix timestamp\n",
    "    df, converted = convert_only_non_numeric_dates_to_unix(\n",
    "        df,\n",
    "        id_col=id_col_eff,\n",
    "        numeric_min_valid_fraction=NUMERIC_MIN_VALID_FRACTION,\n",
    "        date_min_valid_fraction=DATE_MIN_VALID_FRACTION,\n",
    "        unit=UNIX_UNIT,\n",
    "    )\n",
    "    if converted:\n",
    "        logging.info(f\"Converted {len(converted)} non-numeric date-like column(s) to Unix {UNIX_UNIT}: {converted}\")\n",
    "\n",
    "    # 2) Split numeric columns into A and B\n",
    "    cols_A, cols_B = split_numeric_columns(\n",
    "        df, id_col=id_col_eff,\n",
    "        mode=column_split_mode, shuffle=column_split_shuffle, seed=seed,\n",
    "        explicit_A=explicit_cols_A, explicit_B=explicit_cols_B,\n",
    "    )\n",
    "    logging.info(f\"[{os.path.basename(source_file)}] Column split: A={len(cols_A)} cols, B={len(cols_B)} cols\")\n",
    "\n",
    "    # 3) Coerce chosen cols to numeric (cleaning commas/spaces)\n",
    "    df = as_numeric(df, cols_A + cols_B)\n",
    "\n",
    "    A = df[[id_col_eff] + cols_A].copy()\n",
    "    B = df[[id_col_eff] + cols_B].copy()\n",
    "    XA = A[cols_A].to_numpy(dtype=float)\n",
    "    XB = B[cols_B].to_numpy(dtype=float)\n",
    "\n",
    "    # 4) Standardize per side\n",
    "    ZA = zscore(XA.copy()); ZB = zscore(XB.copy())\n",
    "    PA = percentile_rank_matrix(XA.copy()); PB = percentile_rank_matrix(XB.copy())\n",
    "\n",
    "    n = len(df)\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Need at least 2 rows to form negatives.\")\n",
    "\n",
    "    # 5) Build pairs for every row\n",
    "    pos_pairs, neg_pairs = [], []\n",
    "    all_indices = np.arange(n)\n",
    "    for i in range(n):\n",
    "        pos_pairs.append((i, i))\n",
    "        size = min(negatives_per_positive, n - 1)\n",
    "        if size > 0:\n",
    "            candidates = np.delete(all_indices, i)\n",
    "            choices = rng.choice(candidates, size=size, replace=False)\n",
    "            for j in choices:\n",
    "                neg_pairs.append((i, j))\n",
    "\n",
    "    # 6) Compute features + labels + index\n",
    "    X_rows, y_rows, idx_rows = [], [], []\n",
    "    for (i, j) in pos_pairs:\n",
    "        feats = pair_features_numeric(XA[i], XB[j], ZA[i], ZB[j], PA[i], PB[j])\n",
    "        X_rows.append(feats); y_rows.append(1)\n",
    "        idx_rows.append({\n",
    "            \"idA\": A[id_col_eff].iloc[i], \"idB\": B[id_col_eff].iloc[j],\n",
    "            \"row_idx_A\": i, \"row_idx_B\": j, \"label_type\": \"pos\",\n",
    "            \"source_file\": os.path.basename(source_file)\n",
    "        })\n",
    "    for (i, j) in neg_pairs:\n",
    "        feats = pair_features_numeric(XA[i], XB[j], ZA[i], ZB[j], PA[i], PB[j])\n",
    "        X_rows.append(feats); y_rows.append(0)\n",
    "        idx_rows.append({\n",
    "            \"idA\": A[id_col_eff].iloc[i], \"idB\": B[id_col_eff].iloc[j],\n",
    "            \"row_idx_A\": i, \"row_idx_B\": j, \"label_type\": \"neg\",\n",
    "            \"source_file\": os.path.basename(source_file)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(X_rows), pd.Series(y_rows, name=\"label\"), pd.DataFrame(idx_rows)\n",
    "\n",
    "\n",
    "def _apply_row_cap(df: pd.DataFrame, cap: int, mode: str, seed: int) -> pd.DataFrame:\n",
    "    if cap is None or len(df) <= cap:\n",
    "        return df\n",
    "    if mode == \"sample\":\n",
    "        return df.sample(n=cap, random_state=seed)\n",
    "    return df.head(cap)\n",
    "\n",
    "\n",
    "def save_combined_with_ids_and_drop(X: pd.DataFrame, y: pd.Series, idx: pd.DataFrame, out_path: str, drop_cols: List[str]):\n",
    "    \"\"\"\n",
    "    Concatenate IDs/meta + features + label, drop requested columns, and save.\n",
    "    \"\"\"\n",
    "    df_combined = pd.concat(\n",
    "        [idx.reset_index(drop=True), X.reset_index(drop=True), y.reset_index(drop=True)], axis=1\n",
    "    )\n",
    "    # Drop requested columns if present\n",
    "    drop_present = [c for c in drop_cols if c in df_combined.columns]\n",
    "    if drop_present:\n",
    "        df_combined = df_combined.drop(columns=drop_present)\n",
    "        logging.info(f\"Dropped from output: {drop_present}\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(out_path)) or \".\", exist_ok=True)\n",
    "    ext = os.path.splitext(out_path)[1].lower()\n",
    "    if ext == \".parquet\":\n",
    "        df_combined.to_parquet(out_path, index=False)\n",
    "    else:\n",
    "        df_combined.to_csv(out_path, index=False)\n",
    "    logging.info(f\"Combined saved: {out_path} | rows={len(df_combined):,}, cols={df_combined.shape[1]:,}\")\n",
    "\n",
    "\n",
    "def build_pairs_from_dir_column_split(\n",
    "    in_dir: str,\n",
    "    *,\n",
    "    glob_pattern: str = \"*.csv\",\n",
    "    recursive: bool = False,\n",
    "    id_col: Optional[str] = None,\n",
    "    negatives_per_positive: int = 9,\n",
    "    seed: int = 42,\n",
    "    combined_out: str = \"Thesis II/Datasets/XGB_Train/pairs_combined_with_ids.csv\",\n",
    "    log_every_files: int = 10,\n",
    "    row_limit: Optional[int] = None,\n",
    "    row_limit_mode: str = \"head\",\n",
    "    column_split_mode: str = \"half\",\n",
    "    column_split_shuffle: bool = False,\n",
    "    explicit_cols_A: Optional[List[str]] = None,\n",
    "    explicit_cols_B: Optional[List[str]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-CSV orchestrator (column split pipeline with selective date→Unix conversion).\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Find files\n",
    "    search = os.path.join(in_dir, \"**\", glob_pattern) if recursive else os.path.join(in_dir, glob_pattern)\n",
    "    files = sorted(glob.glob(search, recursive=recursive))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matched: {search}\")\n",
    "    logging.info(f\"Found {len(files):,} CSV files\")\n",
    "\n",
    "    all_X, all_y, all_idx = [], [], []\n",
    "    total_pos, total_neg = 0, 0\n",
    "\n",
    "    for k, f in enumerate(files, 1):\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "        # Row cap\n",
    "        original_rows = len(df)\n",
    "        df = _apply_row_cap(df, row_limit, row_limit_mode, seed)\n",
    "        if len(df) < original_rows:\n",
    "            logging.info(f\"[{k}/{len(files)}] {os.path.basename(f)} — capped {original_rows:,} -> {len(df):,} rows\")\n",
    "\n",
    "        if len(df) < 2:\n",
    "            logging.warning(f\"[{k}/{len(files)}] {os.path.basename(f)} has <2 rows after capping; skipping.\")\n",
    "            continue\n",
    "\n",
    "        logging.info(f\"[{k}/{len(files)}] {os.path.basename(f)} — rows={len(df):,}, cols={len(df.columns):,}\")\n",
    "\n",
    "        X, y, idx = build_pairs_from_single_df_column_split(\n",
    "            df=df,\n",
    "            id_col=id_col,\n",
    "            negatives_per_positive=negatives_per_positive,\n",
    "            seed=seed,\n",
    "            source_file=f,\n",
    "            column_split_mode=column_split_mode,\n",
    "            column_split_shuffle=column_split_shuffle,\n",
    "            explicit_cols_A=explicit_cols_A,\n",
    "            explicit_cols_B=explicit_cols_B,\n",
    "        )\n",
    "\n",
    "        all_X.append(X); all_y.append(y); all_idx.append(idx)\n",
    "        pos = int(y.sum()); neg = len(y) - pos\n",
    "        total_pos += pos; total_neg += neg\n",
    "\n",
    "        if k % log_every_files == 0:\n",
    "            logging.info(f\"  Progress: {k:,}/{len(files):,} files | \"\n",
    "                         f\"pairs so far={total_pos+total_neg:,} (pos={total_pos:,}, neg={total_neg:,})\")\n",
    "\n",
    "    if not all_y:\n",
    "        raise RuntimeError(\"No valid CSVs produced pairs (check input files).\")\n",
    "\n",
    "    # Concatenate\n",
    "    X = pd.concat(all_X, axis=0, ignore_index=True)\n",
    "    y = pd.concat(all_y, axis=0, ignore_index=True)\n",
    "    idx = pd.concat(all_idx, axis=0, ignore_index=True)\n",
    "\n",
    "    logging.info(f\"FINAL — pairs={len(y):,} (pos={int(y.sum()):,}, neg={len(y)-int(y.sum()):,}), features={X.shape[1]:,}\")\n",
    "\n",
    "    # Save combined, dropping unwanted columns\n",
    "    save_combined_with_ids_and_drop(X, y, idx, combined_out, drop_cols=DROP_FROM_OUTPUT)\n",
    "\n",
    "    logging.info(f\"Total elapsed: {time.perf_counter() - t0:.2f}s\")\n",
    "    return X, y, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:50:37 | INFO    | Found 25 CSV files\n",
      "2025-09-28 22:50:38 | INFO    | [1/25] AAPL.csv — capped 987,754 -> 10,000 rows\n",
      "2025-09-28 22:50:38 | INFO    | [1/25] AAPL.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:50:38 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:50:38 | INFO    | [AAPL.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:50:47 | INFO    | [2/25] AMZN.csv — capped 824,787 -> 10,000 rows\n",
      "2025-09-28 22:50:47 | INFO    | [2/25] AMZN.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:50:47 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:50:47 | INFO    | [AMZN.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:50:56 | INFO    | [3/25] BA.csv — capped 664,841 -> 10,000 rows\n",
      "2025-09-28 22:50:56 | INFO    | [3/25] BA.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:50:56 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:50:56 | INFO    | [BA.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:05 | INFO    | [4/25] BAC.csv — capped 711,603 -> 10,000 rows\n",
      "2025-09-28 22:51:05 | INFO    | [4/25] BAC.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:05 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:05 | INFO    | [BAC.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:14 | INFO    | [5/25] C.csv — capped 602,400 -> 10,000 rows\n",
      "2025-09-28 22:51:14 | INFO    | [5/25] C.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:14 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:14 | INFO    | [C.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:23 | INFO    | [6/25] CAT.csv — capped 515,453 -> 10,000 rows\n",
      "2025-09-28 22:51:23 | INFO    | [6/25] CAT.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:23 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:23 | INFO    | [CAT.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:32 | INFO    | [7/25] COP.csv — capped 524,679 -> 10,000 rows\n",
      "2025-09-28 22:51:32 | INFO    | [7/25] COP.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:32 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:32 | INFO    | [COP.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:41 | INFO    | [8/25] COST.csv — capped 507,316 -> 10,000 rows\n",
      "2025-09-28 22:51:41 | INFO    | [8/25] COST.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:41 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:41 | INFO    | [COST.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:50 | INFO    | [9/25] CVX.csv — capped 565,757 -> 10,000 rows\n",
      "2025-09-28 22:51:50 | INFO    | [9/25] CVX.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:50 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:50 | INFO    | [CVX.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:51:59 | INFO    | [10/25] GOOGL.csv — capped 708,987 -> 10,000 rows\n",
      "2025-09-28 22:51:59 | INFO    | [10/25] GOOGL.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:51:59 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:51:59 | INFO    | [GOOGL.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:08 | INFO    |   Progress: 10/25 files | pairs so far=1,000,000 (pos=100,000, neg=900,000)\n",
      "2025-09-28 22:52:08 | INFO    | [11/25] GS.csv — capped 516,742 -> 10,000 rows\n",
      "2025-09-28 22:52:08 | INFO    | [11/25] GS.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:08 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:08 | INFO    | [GS.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:17 | INFO    | [12/25] HD.csv — capped 518,910 -> 10,000 rows\n",
      "2025-09-28 22:52:17 | INFO    | [12/25] HD.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:17 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:17 | INFO    | [HD.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:26 | INFO    | [13/25] HON.csv — capped 502,235 -> 10,000 rows\n",
      "2025-09-28 22:52:26 | INFO    | [13/25] HON.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:26 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:26 | INFO    | [HON.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:35 | INFO    | [14/25] JNJ.csv — capped 528,457 -> 10,000 rows\n",
      "2025-09-28 22:52:35 | INFO    | [14/25] JNJ.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:35 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:35 | INFO    | [JNJ.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:44 | INFO    | [15/25] JPM.csv — capped 578,581 -> 10,000 rows\n",
      "2025-09-28 22:52:44 | INFO    | [15/25] JPM.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:44 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:44 | INFO    | [JPM.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:52:53 | INFO    | [16/25] META.csv — capped 557,072 -> 10,000 rows\n",
      "2025-09-28 22:52:53 | INFO    | [16/25] META.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:52:53 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:52:53 | INFO    | [META.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:02 | INFO    | [17/25] MRK.csv — capped 538,258 -> 10,000 rows\n",
      "2025-09-28 22:53:02 | INFO    | [17/25] MRK.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:02 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:02 | INFO    | [MRK.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:10 | INFO    | [18/25] MS.csv — capped 533,814 -> 10,000 rows\n",
      "2025-09-28 22:53:10 | INFO    | [18/25] MS.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:11 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:11 | INFO    | [MS.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:20 | INFO    | [19/25] MSFT.csv — capped 774,618 -> 10,000 rows\n",
      "2025-09-28 22:53:20 | INFO    | [19/25] MSFT.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:20 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:20 | INFO    | [MSFT.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:29 | INFO    | [20/25] NVDA.csv — capped 979,075 -> 10,000 rows\n",
      "2025-09-28 22:53:29 | INFO    | [20/25] NVDA.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:29 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:29 | INFO    | [NVDA.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:38 | INFO    |   Progress: 20/25 files | pairs so far=2,000,000 (pos=200,000, neg=1,800,000)\n",
      "2025-09-28 22:53:38 | INFO    | [21/25] PFE.csv — capped 723,840 -> 10,000 rows\n",
      "2025-09-28 22:53:38 | INFO    | [21/25] PFE.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:38 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:38 | INFO    | [PFE.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:47 | INFO    | [22/25] T.csv — capped 666,832 -> 10,000 rows\n",
      "2025-09-28 22:53:47 | INFO    | [22/25] T.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:47 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:47 | INFO    | [T.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:53:56 | INFO    | [23/25] VZ.csv — capped 601,452 -> 10,000 rows\n",
      "2025-09-28 22:53:56 | INFO    | [23/25] VZ.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:53:56 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:53:56 | INFO    | [VZ.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:54:05 | INFO    | [24/25] WMT.csv — capped 579,428 -> 10,000 rows\n",
      "2025-09-28 22:54:05 | INFO    | [24/25] WMT.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:54:05 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:54:05 | INFO    | [WMT.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:54:14 | INFO    | [25/25] XOM.csv — capped 638,464 -> 10,000 rows\n",
      "2025-09-28 22:54:14 | INFO    | [25/25] XOM.csv — rows=10,000, cols=8\n",
      "2025-09-28 22:54:14 | INFO    | Converted 1 non-numeric date-like column(s) to Unix s: ['ts']\n",
      "2025-09-28 22:54:14 | INFO    | [XOM.csv] Column split: A=4 cols, B=4 cols\n",
      "2025-09-28 22:54:23 | INFO    | FINAL — pairs=2,500,000 (pos=250,000, neg=2,250,000), features=14\n",
      "2025-09-28 22:54:23 | INFO    | Dropped from output: ['num_nan_a', 'num_nan_b', 'num_nan_mismatch', 'row_idx_A', 'row_idx_B', 'label_type', 'source_file']\n",
      "2025-09-28 22:54:46 | INFO    | Combined saved: ../Datasets/XGB_Train/pairs_combined_with_ids.csv | rows=2,500,000, cols=14\n",
      "2025-09-28 22:54:46 | INFO    | Total elapsed: 248.37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved: ../Datasets/XGB_Train/pairs_combined_with_ids.csv\n",
      "Shapes — X: (2500000, 14) | y: (2500000,) | idx: (2500000, 6)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# RUN — execute this cell\n",
    "# ============================================\n",
    "setup_logging(LOG_LEVEL, LOG_FILE)\n",
    "\n",
    "X_all, y_all, idx_all = build_pairs_from_dir_column_split(\n",
    "    in_dir=IN_DIR,\n",
    "    glob_pattern=GLOB_PATTERN,\n",
    "    recursive=RECURSIVE,\n",
    "    id_col=ID_COL,\n",
    "    negatives_per_positive=NEG_PER_POS,\n",
    "    seed=42,\n",
    "    combined_out=COMBINED_OUT,\n",
    "    log_every_files=LOG_EVERY_FILES,\n",
    "    row_limit=ROW_LIMIT,\n",
    "    row_limit_mode=ROW_LIMIT_MODE,\n",
    "    column_split_mode=COLUMN_SPLIT_MODE,\n",
    "    column_split_shuffle=COLUMN_SPLIT_SHUFFLE,\n",
    "    explicit_cols_A=EXPLICIT_COLS_A,\n",
    "    explicit_cols_B=EXPLICIT_COLS_B,\n",
    ")\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Saved:\", COMBINED_OUT)\n",
    "print(\"Shapes — X:\", X_all.shape, \"| y:\", y_all.shape, \"| idx:\", idx_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | rows=1,875,000 | label counts: {0: 1687500, 1: 187500} | ratio: {0: 0.9, 1: 0.1}\n",
      " val  | rows=250,000 | label counts: {0: 225000, 1: 25000} | ratio: {0: 0.9, 1: 0.1}\n",
      "test  | rows=375,000 | label counts: {0: 337500, 1: 37500} | ratio: {0: 0.9, 1: 0.1}\n",
      "\n",
      "Saved:\n",
      " - ../Datasets/XGB_Train/train.csv\n",
      " - ../Datasets/XGB_Train/val.csv\n",
      " - ../Datasets/XGB_Train/test.csv\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# CONFIG\n",
    "# ===========================\n",
    "COMBINED_PATH = \"../Datasets/XGB_Train/pairs_combined_with_ids.csv\"\n",
    "OUT_DIR = \"../Datasets/XGB_Train\"\n",
    "\n",
    "TRAIN_FRACTION = 0.75\n",
    "VAL_FRACTION   = 0.10\n",
    "TEST_FRACTION  = 0.15\n",
    "SEED = 42\n",
    "\n",
    "assert abs(TRAIN_FRACTION + VAL_FRACTION + TEST_FRACTION - 1.0) < 1e-9, \"Fractions must sum to 1.0\"\n",
    "\n",
    "# ===========================\n",
    "# IMPLEMENTATION\n",
    "# ===========================\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(COMBINED_PATH)\n",
    "assert \"label\" in df.columns, \"Expected a 'label' column in the combined dataset.\"\n",
    "\n",
    "# If you want to model only on the numeric feature columns, you can select them here.\n",
    "# The splitter only needs 'label' to stratify, but we keep the full rows so you\n",
    "# can decide later what columns to use in training.\n",
    "y = df[\"label\"]\n",
    "\n",
    "# --- First split: train vs temp (val+test) ---\n",
    "test_val_size = VAL_FRACTION + TEST_FRACTION\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=test_val_size, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# --- Second split: val vs test (from temp) ---\n",
    "# We need to compute the *relative* size of val inside temp\n",
    "rel_val = VAL_FRACTION / (VAL_FRACTION + TEST_FRACTION)\n",
    "temp_y = temp_df[\"label\"]\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=(1 - rel_val), random_state=SEED, stratify=temp_y\n",
    ")\n",
    "\n",
    "# Sanity checks: class balance & sizes\n",
    "def summarize(split_name, d):\n",
    "    counts = d[\"label\"].value_counts(dropna=False).sort_index()\n",
    "    pct = (counts / len(d)).round(4)\n",
    "    print(f\"{split_name:>5} | rows={len(d):,} | label counts: {counts.to_dict()} | ratio: {pct.to_dict()}\")\n",
    "\n",
    "summarize(\"train\", train_df)\n",
    "summarize(\" val \", val_df)\n",
    "summarize(\"test \", test_df)\n",
    "\n",
    "# Save splits (CSV). You can change to .parquet if preferred.\n",
    "train_path = os.path.join(OUT_DIR, \"train.csv\")\n",
    "val_path   = os.path.join(OUT_DIR, \"val.csv\")\n",
    "test_path  = os.path.join(OUT_DIR, \"test.csv\")\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", train_path)\n",
    "print(\" -\", val_path)\n",
    "print(\" -\", test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports + small GPU/CPU helper\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, accuracy_score,\n",
    "    precision_recall_fscore_support, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def gpu_params_for_xgb():\n",
    "    \"\"\"\n",
    "    Return (params_update_dict, description).\n",
    "    Prefers GPU if your xgboost build supports it.\n",
    "    \"\"\"\n",
    "    ver = tuple(int(x) for x in xgb.__version__.split(\".\")[:2])\n",
    "    if ver >= (2, 0):\n",
    "        # XGBoost 2.x\n",
    "        return ({\"device\": \"cuda\", \"tree_method\": \"hist\"}, \"XGB>=2: device=cuda, tree_method=hist\")\n",
    "    else:\n",
    "        # XGBoost 1.x\n",
    "        return ({\"tree_method\": \"gpu_hist\", \"predictor\": \"gpu_predictor\"}, \"XGB<2: tree_method=gpu_hist, predictor=gpu_predictor\")\n",
    "\n",
    "def try_gpu_or_fallback(base_params):\n",
    "    \"\"\"Try a 1-iter train to confirm GPU; fall back to CPU hist if not available.\"\"\"\n",
    "    gpu_update, note = gpu_params_for_xgb()\n",
    "    params = base_params.copy()\n",
    "    params.update(gpu_update)\n",
    "    try:\n",
    "        dm = xgb.DMatrix(np.array([[0.0],[1.0]], dtype=np.float32), label=np.array([0,1], dtype=np.int32))\n",
    "        xgb.train(params, dm, num_boost_round=1)\n",
    "        print(f\"[INFO] Using GPU -> {note}\")\n",
    "        return params\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] GPU not available ({e}). Falling back to CPU (tree_method='hist').\")\n",
    "        params = base_params.copy()\n",
    "        params.update({\"tree_method\": \"hist\"})\n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths & core config\n",
    "\n",
    "DATA_DIR   = \"../Datasets/XGB_Train\"\n",
    "TRAIN_PATH = f\"{DATA_DIR}/train.csv\"\n",
    "VAL_PATH   = f\"{DATA_DIR}/val.csv\"\n",
    "TEST_PATH  = f\"{DATA_DIR}/test.csv\"\n",
    "\n",
    "MODEL_OUT    = f\"{DATA_DIR}/xgb_model.json\"\n",
    "FEATURES_OUT = f\"{DATA_DIR}/xgb_features.txt\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Threshold criterion: \"f1\" (balanced) or \"youden\" (TPR - FPR)\n",
    "THRESHOLD_CRITERION = \"f1\"\n",
    "\n",
    "# Standardization (XGBoost doesn't require it; keep True if you want it)\n",
    "USE_SCALER = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: train=1,875,000, val=250,000, test=375,000\n"
     ]
    }
   ],
   "source": [
    "# Load splits\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df   = pd.read_csv(VAL_PATH)\n",
    "test_df  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "assert \"label\" in train_df.columns and \"label\" in val_df.columns and \"label\" in test_df.columns\n",
    "print(f\"Loaded: train={len(train_df):,}, val={len(val_df):,}, test={len(test_df):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used (12): ['absdiff_mean', 'absdiff_median', 'reldiff_mean', 'zdiff_mean', 'pcdiff_mean', 'L1_raw', 'L2_raw', 'L1_z', 'L2_z', 'L1_pct'] ...\n"
     ]
    }
   ],
   "source": [
    "# Select numeric features (drop obvious IDs/meta)\n",
    "\n",
    "id_like = {\"idA\", \"idB\", \"row_idx_A\", \"row_idx_B\", \"label_type\", \"source_file\"}\n",
    "drop_cols = [c for c in train_df.columns if c in id_like or c == \"label\"]\n",
    "\n",
    "num_cols = [c for c in train_df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(train_df[c])]\n",
    "assert len(num_cols) > 0, \"No numeric feature columns found.\"\n",
    "\n",
    "X_train = train_df[num_cols].to_numpy(dtype=float)\n",
    "y_train = train_df[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "X_val   = val_df[num_cols].to_numpy(dtype=float)\n",
    "y_val   = val_df[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "X_test  = test_df[num_cols].to_numpy(dtype=float)\n",
    "y_test  = test_df[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "print(f\"Features used ({len(num_cols)}): {num_cols[:10]}{' ...' if len(num_cols)>10 else ''}\")\n",
    "\n",
    "# Optional standardization\n",
    "if USE_SCALER:\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "    X_test  = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight (train): 9.000  (pos=187500, neg=1687500)\n",
      "Using preset: recall_oriented \n",
      " {'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.0, 'reg_lambda': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Compute scale_pos_weight from TRAIN split\n",
    "\n",
    "pos = y_train.sum()\n",
    "neg = len(y_train) - pos\n",
    "spw = (neg / max(pos, 1)) if pos > 0 else 1.0\n",
    "print(f\"scale_pos_weight (train): {spw:.3f}  (pos={pos}, neg={neg})\")\n",
    "\n",
    "# Define presets and pick one\n",
    "\n",
    "PRESETS = {\n",
    "    \"baseline\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 6,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.0,\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        # uses scale_pos_weight from Cell 5\n",
    "    },\n",
    "    \"fp_averse\": {  # precision-leaning\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 5,         # ↓\n",
    "        \"min_child_weight\": 8,  # ↑\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.7, # ↓\n",
    "        \"gamma\": 1.0,           # ↑\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 3.0,      # ↑\n",
    "    },\n",
    "    \"recall_oriented\": {\n",
    "        \"learning_rate\": 0.03,  # ↓\n",
    "        \"max_depth\": 7,         # ↑\n",
    "        \"min_child_weight\": 2,  # ↓\n",
    "        \"subsample\": 0.9,       # ↑\n",
    "        \"colsample_bytree\": 0.9,# ↑\n",
    "        \"gamma\": 0.0,\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 1.0,\n",
    "        # tip: you can reduce spw effect by multiplying it later (e.g., 0.7*spw)\n",
    "    },\n",
    "    \"overfit_guarded\": {\n",
    "        \"learning_rate\": 0.06,  # ↑\n",
    "        \"max_depth\": 4,         # ↓\n",
    "        \"min_child_weight\": 10, # ↑\n",
    "        \"subsample\": 0.7,       # ↓\n",
    "        \"colsample_bytree\": 0.7,# ↓\n",
    "        \"gamma\": 2.0,           # ↑\n",
    "        \"reg_alpha\": 0.5,       # ↑ (L1)\n",
    "        \"reg_lambda\": 8.0,      # ↑ (L2)\n",
    "    },\n",
    "    \"gpu_large\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 6,\n",
    "        \"min_child_weight\": 6,  # ↑\n",
    "        \"subsample\": 0.85,      # ↑\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"gamma\": 0.5,           # ↑\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 2.0,      # ↑\n",
    "        \"max_bin\": 512,         # new (GPU hist quality)\n",
    "    },\n",
    "}\n",
    "\n",
    "PRESET_NAME = \"recall_oriented\"  # <-- choose: baseline | fp_averse | recall_oriented | overfit_guarded | gpu_large \n",
    "preset = PRESETS[PRESET_NAME]\n",
    "print(\"Using preset:\", PRESET_NAME, \"\\n\", preset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU -> XGB>=2: device=cuda, tree_method=hist\n",
      "[0]\ttrain-auc:0.99509\tval-auc:0.92082\n",
      "[200]\ttrain-auc:0.99520\tval-auc:0.95759\n",
      "[400]\ttrain-auc:0.99539\tval-auc:0.95441\n",
      "[600]\ttrain-auc:0.99568\tval-auc:0.93870\n",
      "[800]\ttrain-auc:0.99595\tval-auc:0.92669\n",
      "[1000]\ttrain-auc:0.99618\tval-auc:0.92204\n",
      "[1200]\ttrain-auc:0.99641\tval-auc:0.91777\n",
      "[1248]\ttrain-auc:0.99646\tval-auc:0.91696\n",
      "Stopped at iteration: 248  | Best val AUC: 0.9576907373333333\n"
     ]
    }
   ],
   "source": [
    "# ---- knobs you can tweak ----\n",
    "NUM_BOOST_ROUND = 40_000     # max rounds (early stopping may halt sooner)\n",
    "PATIENCE        = 1_000       # rounds with no val AUC improvement before stopping\n",
    "VERBOSE_EVAL    = 200         # print every N rounds\n",
    "USE_LR_SCHEDULE = True        # set False to keep fixed learning_rate from params\n",
    "\n",
    "# Learning-rate schedule options (choose one style below)\n",
    "def lr_step_decay(base_lr, step_size=2_000, decay=0.5):\n",
    "    \"\"\"\n",
    "    Halve lr every `step_size` rounds: 0..1999: lr, 2000..3999: lr*0.5, etc.\n",
    "    \"\"\"\n",
    "    def _sched(round_idx):\n",
    "        from math import floor\n",
    "        k = floor(round_idx / step_size)\n",
    "        return base_lr * (decay ** k)\n",
    "    return _sched\n",
    "\n",
    "def lr_cosine_decay(base_lr, min_lr=0.005, total_rounds=50_000):\n",
    "    \"\"\"\n",
    "    Cosine annealing from base_lr -> min_lr over `total_rounds`, then flat.\n",
    "    \"\"\"\n",
    "    import math\n",
    "    def _sched(round_idx):\n",
    "        if round_idx >= total_rounds:\n",
    "            return min_lr\n",
    "        cos = (1 + math.cos(math.pi * round_idx / total_rounds)) / 2.0\n",
    "        return min_lr + (base_lr - min_lr) * cos\n",
    "    return _sched\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- build params with GPU/CPU selection (reuse from earlier cells) ----\n",
    "base_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"random_state\": SEED,\n",
    "    \"scale_pos_weight\": base_params.get(\"scale_pos_weight\", spw) if 'base_params' in globals() else spw,\n",
    "}\n",
    "# if you already created `preset` in Cell 6:\n",
    "params = base_params.copy(); params.update(preset)\n",
    "params = try_gpu_or_fallback(params)\n",
    "\n",
    "# Pick ONE schedule to use if USE_LR_SCHEDULE is True (now params is defined)\n",
    "if USE_LR_SCHEDULE:\n",
    "    lr_scheduler = lr_step_decay(\n",
    "        base_lr=params.get(\"learning_rate\", 0.05),\n",
    "        step_size=3_000,\n",
    "        decay=0.5\n",
    "    )\n",
    "    # Or choose cosine:\n",
    "    # lr_scheduler = lr_cosine_decay(\n",
    "    #     base_lr=params.get(\"learning_rate\", 0.05),\n",
    "    #     min_lr=0.005,\n",
    "    #     total_rounds=60_000\n",
    "    # )\n",
    "else:\n",
    "    lr_scheduler = None\n",
    "\n",
    "\n",
    "# ---- data matrices ----\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=num_cols)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val,   feature_names=num_cols)\n",
    "dtest  = xgb.DMatrix(X_test,  label=y_test,  feature_names=num_cols)   # NEW\n",
    "\n",
    "\n",
    "# ---- callbacks ----\n",
    "callbacks = [\n",
    "    xgb.callback.EarlyStopping(\n",
    "        rounds=PATIENCE,\n",
    "        save_best=True,          # keep best iteration\n",
    "        maximize=True            # AUC is to be maximized\n",
    "    )\n",
    "]\n",
    "if USE_LR_SCHEDULE:\n",
    "    callbacks.append(xgb.callback.LearningRateScheduler(lr_scheduler))\n",
    "\n",
    "# ---- train ----\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=NUM_BOOST_ROUND,\n",
    "    evals=evals,\n",
    "    verbose_eval=VERBOSE_EVAL,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(f\"Stopped at iteration: {bst.best_iteration}  | Best val AUC: {bst.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold (f1): 0.770  | score=0.7412\n",
      "[INFO] compat_score added and splits overwritten: ../Datasets/XGB_Train/train.csv ../Datasets/XGB_Train/val.csv ../Datasets/XGB_Train/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Pick decision threshold from validation set\n",
    "\n",
    "def pick_threshold(y_true, p, method=\"f1\"):\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    best_t, best_score = 0.5, -1\n",
    "    for t in thresholds:\n",
    "        y_hat = (p >= t).astype(int)\n",
    "        if method == \"f1\":\n",
    "            prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_hat, average=\"binary\", zero_division=0)\n",
    "            score = f1\n",
    "        elif method == \"youden\":\n",
    "            tp = np.sum((y_true == 1) & (y_hat == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_hat == 0))\n",
    "            fp = np.sum((y_true == 0) & (y_hat == 1))\n",
    "            tn = np.sum((y_true == 0) & (y_hat == 0))\n",
    "            tpr = tp / max(tp + fn, 1)  # recall\n",
    "            fpr = fp / max(fp + tn, 1)\n",
    "            score = tpr - fpr\n",
    "        else:\n",
    "            raise ValueError(\"Unknown method\")\n",
    "        if score > best_score:\n",
    "            best_score, best_t = score, t\n",
    "    return best_t, best_score\n",
    "\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=num_cols)\n",
    "val_pred_proba = bst.predict(dval, iteration_range=(0, bst.best_iteration+1))\n",
    "\n",
    "best_thresh, best_val_score = pick_threshold(y_val, val_pred_proba, method=THRESHOLD_CRITERION)\n",
    "print(f\"Chosen threshold ({THRESHOLD_CRITERION}): {best_thresh:.3f}  | score={best_val_score:.4f}\")\n",
    "\n",
    "# --- NEW: add compat_score to each split and overwrite the same files ---\n",
    "train_pred_proba = bst.predict(dtrain, iteration_range=(0, bst.best_iteration + 1))\n",
    "test_pred_proba  = bst.predict(dtest,  iteration_range=(0, bst.best_iteration + 1))\n",
    "\n",
    "train_df[\"compat_score\"] = train_pred_proba.astype(float)\n",
    "val_df[\"compat_score\"]   = val_pred_proba.astype(float)   # already computed above\n",
    "test_df[\"compat_score\"]  = test_pred_proba.astype(float)\n",
    "\n",
    "# Overwrite in place (no new files)\n",
    "train_df.to_csv(TRAIN_PATH, index=False)\n",
    "val_df.to_csv(VAL_PATH, index=False)\n",
    "test_df.to_csv(TEST_PATH, index=False)\n",
    "print(\"[INFO] compat_score added and splits overwritten:\", TRAIN_PATH, VAL_PATH, TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[VAL]\n",
      "ROC-AUC=0.9577 | PR-AUC=0.7603 | ACC=0.9444 | P=0.6932 | R=0.7963 | F1=0.7412\n",
      "Confusion matrix (tn, fp; fn, tp):\n",
      "[[216191   8809]\n",
      " [  5093  19907]]\n",
      "\n",
      "[TEST]\n",
      "ROC-AUC=0.9572 | PR-AUC=0.7567 | ACC=0.9438 | P=0.6909 | R=0.7929 | F1=0.7384\n",
      "Confusion matrix (tn, fp; fn, tp):\n",
      "[[324197  13303]\n",
      " [  7767  29733]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_split(name, y_true, proba, threshold):\n",
    "    y_pred = (proba >= threshold).astype(int)\n",
    "    auc = roc_auc_score(y_true, proba)\n",
    "    ap  = average_precision_score(y_true, proba)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(f\"ROC-AUC={auc:.4f} | PR-AUC={ap:.4f} | ACC={acc:.4f} | P={prec:.4f} | R={rec:.4f} | F1={f1:.4f}\")\n",
    "    print(\"Confusion matrix (tn, fp; fn, tp):\")\n",
    "    print(cm)\n",
    "    return {\"auc\": auc, \"ap\": ap, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm}\n",
    "\n",
    "# VAL\n",
    "val_metrics = evaluate_split(\"VAL\", y_val, val_pred_proba, best_thresh)\n",
    "\n",
    "# TEST\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, feature_names=num_cols)\n",
    "test_pred_proba = bst.predict(dtest, iteration_range=(0, bst.best_iteration+1))\n",
    "test_metrics = evaluate_split(\"TEST\", y_test, test_pred_proba, best_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved:\n",
      " - Model: ../Datasets/XGB_Train/xgb_model.json\n",
      " - Features list: ../Datasets/XGB_Train/xgb_features.txt\n",
      "\n",
      "Top features by gain:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gain",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d4ebf9fc-c11b-4245-8264-b4993b8a157c",
       "rows": [
        [
         "0",
         "compat_score",
         "19084.712890625"
        ],
        [
         "1",
         "pcdiff_mean",
         "548.583984375"
        ],
        [
         "2",
         "L2_pct",
         "222.52308654785156"
        ],
        [
         "3",
         "zdiff_mean",
         "197.8230438232422"
        ],
        [
         "4",
         "L2_z",
         "146.2499542236328"
        ],
        [
         "5",
         "reldiff_mean",
         "88.44621276855469"
        ],
        [
         "6",
         "absdiff_mean",
         "47.208988189697266"
        ],
        [
         "7",
         "L1_z",
         "33.24543762207031"
        ],
        [
         "8",
         "absdiff_median",
         "20.655065536499023"
        ],
        [
         "9",
         "L1_pct",
         "18.690515518188477"
        ],
        [
         "10",
         "L1_raw",
         "13.037699699401855"
        ],
        [
         "11",
         "L2_raw",
         "12.953365325927734"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compat_score</td>\n",
       "      <td>19084.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pcdiff_mean</td>\n",
       "      <td>548.583984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L2_pct</td>\n",
       "      <td>222.523087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zdiff_mean</td>\n",
       "      <td>197.823044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L2_z</td>\n",
       "      <td>146.249954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reldiff_mean</td>\n",
       "      <td>88.446213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absdiff_mean</td>\n",
       "      <td>47.208988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L1_z</td>\n",
       "      <td>33.245438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>absdiff_median</td>\n",
       "      <td>20.655066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L1_pct</td>\n",
       "      <td>18.690516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L1_raw</td>\n",
       "      <td>13.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L2_raw</td>\n",
       "      <td>12.953365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature          gain\n",
       "0     compat_score  19084.712891\n",
       "1      pcdiff_mean    548.583984\n",
       "2           L2_pct    222.523087\n",
       "3       zdiff_mean    197.823044\n",
       "4             L2_z    146.249954\n",
       "5     reldiff_mean     88.446213\n",
       "6     absdiff_mean     47.208988\n",
       "7             L1_z     33.245438\n",
       "8   absdiff_median     20.655066\n",
       "9           L1_pct     18.690516\n",
       "10          L1_raw     13.037700\n",
       "11          L2_raw     12.953365"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save artifacts\n",
    "bst.save_model(MODEL_OUT)\n",
    "with open(FEATURES_OUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for c in num_cols:\n",
    "        f.write(f\"{c}\\n\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - Model:\", MODEL_OUT)\n",
    "print(\" - Features list:\", FEATURES_OUT)\n",
    "\n",
    "# Feature importance (gain)\n",
    "importance = bst.get_score(importance_type=\"gain\")\n",
    "imp_df = (pd.DataFrame({\"feature\": list(importance.keys()),\n",
    "                        \"gain\": list(importance.values())})\n",
    "            .sort_values(\"gain\", ascending=False)\n",
    "            .reset_index(drop=True))\n",
    "print(\"\\nTop features by gain:\")\n",
    "display(imp_df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idA==idB: 29356/37500 rows have compat_score > 0.8 -> 78.28%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEST_PATH = \"../Datasets/XGB_Train/test.csv\"  # adjust if needed\n",
    "THRESH = 0.80\n",
    "\n",
    "df = pd.read_csv(TEST_PATH)\n",
    "assert {\"idA\",\"idB\",\"compat_score\"}.issubset(df.columns), \"test.csv must have idA, idB, compat_score\"\n",
    "\n",
    "eq  = df[\"idA\"].astype(str) == df[\"idB\"].astype(str)\n",
    "gt  = df[\"compat_score\"].astype(float) > THRESH   # strict '>' as requested\n",
    "\n",
    "# For idA == idB\n",
    "total_eq = int(eq.sum())\n",
    "hit_eq   = int((eq & gt).sum())\n",
    "pct_eq   = 100.0 * hit_eq / total_eq if total_eq else 0.0\n",
    "\n",
    "print(f\"idA==idB: {hit_eq}/{total_eq} rows have compat_score > {THRESH} -> {pct_eq:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idA!=idB: 12773/337500 rows have compat_score > 0.8 -> 3.78%\n"
     ]
    }
   ],
   "source": [
    "neq       = ~eq\n",
    "total_neq = int(neq.sum())\n",
    "hit_neq   = int((neq & gt).sum())\n",
    "pct_neq   = 100.0 * hit_neq / total_neq if total_neq else 0.0\n",
    "\n",
    "print(f\"idA!=idB: {hit_neq}/{total_neq} rows have compat_score > {THRESH} -> {pct_neq:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# NEW CELL 32: 🔍 DATA LEAKAGE TEST - ADD NOISE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA LEAKAGE DETECTION TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Testing strategy:\n",
    "  1. Add increasing levels of Gaussian noise to test features\n",
    "  2. Re-evaluate model on noisy data\n",
    "  3. Compare metrics to original test performance\n",
    "  \n",
    "Expected behavior:\n",
    "  ✓ NO LEAKAGE: Metrics degrade gradually with noise\n",
    "  ✗ LEAKAGE: Metrics stay high despite noise (model memorized)\n",
    "\"\"\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Load original test data\n",
    "test_df_original = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Extract features (same as before)\n",
    "id_like = {\"idA\", \"idB\", \"row_idx_A\", \"row_idx_B\", \"label_type\", \"source_file\", \"compat_score\"}\n",
    "drop_cols = [c for c in test_df_original.columns if c in id_like or c == \"label\"]\n",
    "num_cols_test = [c for c in test_df_original.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(test_df_original[c])]\n",
    "\n",
    "X_test_clean = test_df_original[num_cols_test].to_numpy(dtype=float)\n",
    "y_test_clean = test_df_original[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "# Apply same standardization as training\n",
    "if USE_SCALER:\n",
    "    X_test_clean_scaled = scaler.transform(X_test_clean)\n",
    "else:\n",
    "    X_test_clean_scaled = X_test_clean\n",
    "\n",
    "print(f\"\\n✓ Loaded test data: {len(X_test_clean):,} samples, {len(num_cols_test)} features\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Function to add Gaussian noise\n",
    "# ============================================\n",
    "def add_gaussian_noise(X, noise_level=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to features.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix (n_samples, n_features)\n",
    "        noise_level: Std dev of noise as fraction of feature std dev\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        X_noisy: Feature matrix with added noise\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X_noisy = X.copy()\n",
    "    \n",
    "    # For each feature, add noise proportional to its std dev\n",
    "    for j in range(X.shape[1]):\n",
    "        feature_std = np.nanstd(X[:, j])\n",
    "        if feature_std > 0:\n",
    "            noise = np.random.normal(0, noise_level * feature_std, size=X.shape[0])\n",
    "            X_noisy[:, j] = X[:, j] + noise\n",
    "    \n",
    "    return X_noisy\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Test with increasing noise levels\n",
    "# ============================================\n",
    "noise_levels = [0.0, 0.05, 0.10, 0.20, 0.30, 0.50, 0.75, 1.0]\n",
    "results_noise_test = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING WITH INCREASING NOISE LEVELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for noise_level in noise_levels:\n",
    "    # Add noise\n",
    "    if noise_level == 0.0:\n",
    "        X_test_noisy = X_test_clean_scaled\n",
    "        noise_desc = \"CLEAN (no noise)\"\n",
    "    else:\n",
    "        X_test_noisy = add_gaussian_noise(X_test_clean_scaled, noise_level=noise_level)\n",
    "        noise_desc = f\"Noise σ = {noise_level:.2f}\"\n",
    "    \n",
    "    # Create DMatrix\n",
    "    dtest_noisy = xgb.DMatrix(X_test_noisy, label=y_test_clean, feature_names=num_cols_test)\n",
    "    \n",
    "    # Predict\n",
    "    test_pred_noisy = bst.predict(dtest_noisy, iteration_range=(0, bst.best_iteration + 1))\n",
    "    \n",
    "    # Evaluate at F2-optimal threshold\n",
    "    y_pred_noisy = (test_pred_noisy >= best_f2_thresh).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    auc = roc_auc_score(y_test_clean, test_pred_noisy)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_clean, y_pred_noisy).ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # Store results\n",
    "    results_noise_test.append({\n",
    "        'noise_level': noise_level,\n",
    "        'auc': auc,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn\n",
    "    })\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{noise_desc:20s} | AUC: {auc:.4f} | F1: {f1:.4f} | P: {precision:.4f} | R: {recall:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Convert to DataFrame for analysis\n",
    "# ============================================\n",
    "results_df = pd.DataFrame(results_noise_test)\n",
    "\n",
    "print(\"\\nDETAILED RESULTS TABLE:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(f\"{DATA_DIR}/leakage_test_results.csv\", index=False)\n",
    "print(f\"\\n✓ Results saved: {DATA_DIR}/leakage_test_results.csv\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# NEW CELL 33: 📊 VISUALIZE NOISE TEST RESULTS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZING LEAKAGE TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: AUC degradation\n",
    "ax = axes[0, 0]\n",
    "ax.plot(results_df['noise_level'], results_df['auc'], 'o-', linewidth=3, markersize=10, color='steelblue')\n",
    "ax.axhline(y=results_df['auc'].iloc[0], color='green', linestyle='--', alpha=0.5, label='Baseline (no noise)')\n",
    "ax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random guessing')\n",
    "ax.set_xlabel('Noise Level (σ)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('AUC', fontsize=13, fontweight='bold')\n",
    "ax.set_title('AUC vs Noise Level', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 2: F1 Score degradation\n",
    "ax = axes[0, 1]\n",
    "ax.plot(results_df['noise_level'], results_df['f1'], 'o-', linewidth=3, markersize=10, color='darkgreen')\n",
    "ax.axhline(y=results_df['f1'].iloc[0], color='green', linestyle='--', alpha=0.5, label='Baseline')\n",
    "ax.set_xlabel('Noise Level (σ)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('F1 Score', fontsize=13, fontweight='bold')\n",
    "ax.set_title('F1 Score vs Noise Level', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 3: Precision and Recall\n",
    "ax = axes[1, 0]\n",
    "ax.plot(results_df['noise_level'], results_df['precision'], 'o-', linewidth=3, markersize=10, \n",
    "        color='blue', label='Precision')\n",
    "ax.plot(results_df['noise_level'], results_df['recall'], 's-', linewidth=3, markersize=10, \n",
    "        color='orange', label='Recall')\n",
    "ax.set_xlabel('Noise Level (σ)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Precision & Recall vs Noise Level', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 4: Relative degradation (%)\n",
    "ax = axes[1, 1]\n",
    "baseline_auc = results_df['auc'].iloc[0]\n",
    "baseline_f1 = results_df['f1'].iloc[0]\n",
    "\n",
    "auc_degradation = (1 - results_df['auc'] / baseline_auc) * 100\n",
    "f1_degradation = (1 - results_df['f1'] / baseline_f1) * 100\n",
    "\n",
    "ax.plot(results_df['noise_level'], auc_degradation, 'o-', linewidth=3, markersize=10, \n",
    "        color='steelblue', label='AUC degradation')\n",
    "ax.plot(results_df['noise_level'], f1_degradation, 's-', linewidth=3, markersize=10, \n",
    "        color='darkgreen', label='F1 degradation')\n",
    "ax.set_xlabel('Noise Level (σ)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Performance Loss (%)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Relative Performance Degradation', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50% loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DATA_DIR}/leakage_test_visualization.png\", dpi=150, bbox_inches='tight')\n",
    "print(f\"✓ Visualization saved: {DATA_DIR}/leakage_test_visualization.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# NEW CELL 34: 🔍 LEAKAGE DIAGNOSIS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA LEAKAGE DIAGNOSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate degradation metrics\n",
    "baseline_auc = results_df['auc'].iloc[0]\n",
    "baseline_f1 = results_df['f1'].iloc[0]\n",
    "\n",
    "auc_at_10pct = results_df[results_df['noise_level'] == 0.10]['auc'].values[0]\n",
    "auc_at_50pct = results_df[results_df['noise_level'] == 0.50]['auc'].values[0]\n",
    "\n",
    "auc_drop_10 = ((baseline_auc - auc_at_10pct) / baseline_auc) * 100\n",
    "auc_drop_50 = ((baseline_auc - auc_at_50pct) / baseline_auc) * 100\n",
    "\n",
    "f1_at_10pct = results_df[results_df['noise_level'] == 0.10]['f1'].values[0]\n",
    "f1_at_50pct = results_df[results_df['noise_level'] == 0.50]['f1'].values[0]\n",
    "\n",
    "f1_drop_10 = ((baseline_f1 - f1_at_10pct) / baseline_f1) * 100\n",
    "f1_drop_50 = ((baseline_f1 - f1_at_50pct) / baseline_f1) * 100\n",
    "\n",
    "print(f\"\\n📊 BASELINE PERFORMANCE (No Noise):\")\n",
    "print(f\"   AUC: {baseline_auc:.4f}\")\n",
    "print(f\"   F1:  {baseline_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n📉 DEGRADATION WITH NOISE:\")\n",
    "print(f\"   At 10% noise (σ=0.10):\")\n",
    "print(f\"      AUC: {auc_at_10pct:.4f} (↓ {auc_drop_10:.1f}%)\")\n",
    "print(f\"      F1:  {f1_at_10pct:.4f} (↓ {f1_drop_10:.1f}%)\")\n",
    "print(f\"   \")\n",
    "print(f\"   At 50% noise (σ=0.50):\")\n",
    "print(f\"      AUC: {auc_at_50pct:.4f} (↓ {auc_drop_50:.1f}%)\")\n",
    "print(f\"      F1:  {f1_at_50pct:.4f} (↓ {f1_drop_50:.1f}%)\")\n",
    "\n",
    "# Diagnosis logic\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LEAKAGE DETECTION VERDICT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "leakage_detected = False\n",
    "warnings = []\n",
    "\n",
    "# Test 1: Is degradation gradual?\n",
    "if auc_drop_10 < 2.0:\n",
    "    warnings.append(\"⚠️  WARNING: AUC barely drops with 10% noise (< 2% loss)\")\n",
    "    warnings.append(\"   → Model may be memorizing patterns or has data leakage\")\n",
    "    leakage_detected = True\n",
    "\n",
    "# Test 2: Does it stay unreasonably high?\n",
    "if auc_at_50pct > 0.85 and baseline_auc > 0.90:\n",
    "    warnings.append(\"⚠️  WARNING: AUC stays very high (>0.85) even with 50% noise\")\n",
    "    warnings.append(\"   → Possible leakage: model shouldn't work this well with heavy noise\")\n",
    "    leakage_detected = True\n",
    "\n",
    "# Test 3: Check if AUC drops below 0.6 at high noise\n",
    "auc_at_100pct = results_df[results_df['noise_level'] == 1.0]['auc'].values[0]\n",
    "if auc_at_100pct > 0.75:\n",
    "    warnings.append(\"⚠️  WARNING: AUC > 0.75 even with 100% noise\")\n",
    "    warnings.append(\"   → Strong indication of data leakage\")\n",
    "    leakage_detected = True\n",
    "\n",
    "# Test 4: Check for reasonable degradation curve\n",
    "expected_drop_50 = 25  # We expect at least 25% drop at 50% noise\n",
    "if auc_drop_50 < expected_drop_50:\n",
    "    warnings.append(f\"⚠️  WARNING: AUC degradation too slow ({auc_drop_50:.1f}% at 50% noise)\")\n",
    "    warnings.append(f\"   → Expected: >{expected_drop_50}% degradation\")\n",
    "    leakage_detected = True\n",
    "\n",
    "# Print verdict\n",
    "if leakage_detected:\n",
    "    print(\"\\n🚨 POTENTIAL DATA LEAKAGE DETECTED!\")\n",
    "    print(\"=\"*80)\n",
    "    for warning in warnings:\n",
    "        print(warning)\n",
    "    \n",
    "    print(\"\\n🔍 RECOMMENDED ACTIONS:\")\n",
    "    print(\"   1. Check if idA/idB are leaking into features\")\n",
    "    print(\"   2. Verify train/val/test split is based on unique IDs\")\n",
    "    print(\"   3. Review feature engineering - are you using future information?\")\n",
    "    print(\"   4. Check for duplicate rows across splits\")\n",
    "    print(\"   5. Ensure same-file pairs aren't in multiple splits\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n✅ NO DATA LEAKAGE DETECTED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   ✓ Performance degrades gracefully with noise\")\n",
    "    print(f\"   ✓ AUC drops {auc_drop_10:.1f}% at 10% noise (reasonable)\")\n",
    "    print(f\"   ✓ AUC drops {auc_drop_50:.1f}% at 50% noise (expected)\")\n",
    "    print(f\"   ✓ Model learned generalizable patterns, not memorization\")\n",
    "    \n",
    "    print(\"\\n📈 EXPECTED BEHAVIOR CONFIRMED:\")\n",
    "    print(\"   • Baseline: Strong performance\")\n",
    "    print(\"   • 10% noise: Slight degradation (model is robust)\")\n",
    "    print(\"   • 50% noise: Significant degradation (model can't handle garbage)\")\n",
    "    print(\"   • 100% noise: Major degradation (as expected)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# NEW CELL 35: 🧪 ADDITIONAL LEAKAGE TESTS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADDITIONAL LEAKAGE TESTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Check for identical features between train and test\n",
    "print(\"\\n🔍 TEST 1: Checking for identical rows...\")\n",
    "\n",
    "train_df_check = pd.read_csv(TRAIN_PATH)\n",
    "test_df_check = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Create signature from feature columns only\n",
    "train_signatures = train_df_check[num_cols_test].apply(\n",
    "    lambda row: hash(tuple(row)), axis=1\n",
    ")\n",
    "test_signatures = test_df_check[num_cols_test].apply(\n",
    "    lambda row: hash(tuple(row)), axis=1\n",
    ")\n",
    "\n",
    "duplicates = set(train_signatures).intersection(set(test_signatures))\n",
    "\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"   🚨 FOUND {len(duplicates)} identical feature rows in train and test!\")\n",
    "    print(\"   → CRITICAL: This is data leakage!\")\n",
    "else:\n",
    "    print(f\"   ✓ No identical feature rows found between train and test\")\n",
    "\n",
    "\n",
    "# Test 2: Check if IDs overlap\n",
    "print(\"\\n🔍 TEST 2: Checking for overlapping IDs...\")\n",
    "\n",
    "train_ids_a = set(train_df_check['idA'].astype(str))\n",
    "train_ids_b = set(train_df_check['idB'].astype(str))\n",
    "train_ids_all = train_ids_a.union(train_ids_b)\n",
    "\n",
    "test_ids_a = set(test_df_check['idA'].astype(str))\n",
    "test_ids_b = set(test_df_check['idB'].astype(str))\n",
    "test_ids_all = test_ids_a.union(test_ids_b)\n",
    "\n",
    "overlapping_ids = train_ids_all.intersection(test_ids_all)\n",
    "\n",
    "print(f\"   Unique IDs in train: {len(train_ids_all):,}\")\n",
    "print(f\"   Unique IDs in test:  {len(test_ids_all):,}\")\n",
    "print(f\"   Overlapping IDs:     {len(overlapping_ids):,}\")\n",
    "\n",
    "if len(overlapping_ids) > 0:\n",
    "    overlap_pct = 100 * len(overlapping_ids) / len(test_ids_all)\n",
    "    print(f\"   ⚠️  {overlap_pct:.1f}% of test IDs also appear in training\")\n",
    "    \n",
    "    if overlap_pct > 50:\n",
    "        print(\"   🚨 HIGH OVERLAP: Potential leakage if same entity pairs in both sets\")\n",
    "    else:\n",
    "        print(\"   ℹ️  Some overlap is OK if pairs are different (e.g., A-B in train, A-C in test)\")\n",
    "else:\n",
    "    print(\"   ✓ No overlapping IDs (completely disjoint)\")\n",
    "\n",
    "\n",
    "# Test 3: Statistical test - are feature distributions too similar?\n",
    "print(\"\\n🔍 TEST 3: Comparing feature distributions...\")\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "feature_similarity_scores = []\n",
    "\n",
    "for col in num_cols_test[:10]:  # Check first 10 features\n",
    "    train_vals = train_df_check[col].dropna().values\n",
    "    test_vals = test_df_check[col].dropna().values\n",
    "    \n",
    "    if len(train_vals) > 100 and len(test_vals) > 100:\n",
    "        # Kolmogorov-Smirnov test\n",
    "        statistic, pvalue = ks_2samp(train_vals, test_vals)\n",
    "        feature_similarity_scores.append({\n",
    "            'feature': col,\n",
    "            'ks_statistic': statistic,\n",
    "            'p_value': pvalue,\n",
    "            'similar': pvalue > 0.05  # If p > 0.05, distributions are similar\n",
    "        })\n",
    "\n",
    "if feature_similarity_scores:\n",
    "    similar_count = sum(1 for f in feature_similarity_scores if f['similar'])\n",
    "    print(f\"   Features with similar distributions: {similar_count}/{len(feature_similarity_scores)}\")\n",
    "    \n",
    "    if similar_count == len(feature_similarity_scores):\n",
    "        print(\"   ✓ Train and test have similar feature distributions (expected)\")\n",
    "    else:\n",
    "        print(f\"   ℹ️  Some features differ between train/test (may be OK if splits are stratified)\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ LEAKAGE TESTING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Summary of all tests:\n",
    "  1. Noise robustness:     {'✓ PASS' if not leakage_detected else '✗ FAIL - check noise test'}\n",
    "  2. Identical rows:       {'✓ PASS' if len(duplicates) == 0 else '✗ FAIL - duplicates found'}\n",
    "  3. ID overlap:           {'✓ PASS' if len(overlapping_ids) < len(test_ids_all)*0.5 else '⚠️  WARNING - high overlap'}\n",
    "  4. Distribution check:   {'✓ PASS' if feature_similarity_scores else 'ℹ️  SKIPPED'}\n",
    "\n",
    "Overall verdict: {'✅ NO LEAKAGE DETECTED' if not leakage_detected and len(duplicates) == 0 else '🚨 POTENTIAL LEAKAGE - INVESTIGATE'}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# NEW CELL 36: 📝 SAVE LEAKAGE TEST REPORT\n",
    "# ============================================\n",
    "leakage_report = f\"\"\"\n",
    "{'='*80}\n",
    "DATA LEAKAGE DETECTION REPORT\n",
    "{'='*80}\n",
    "\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "TEST METHODOLOGY\n",
    "{'-'*80}\n",
    "1. Added Gaussian noise at levels: {', '.join([f'{x:.0%}' for x in noise_levels[1:]])}\n",
    "2. Re-evaluated model on noisy test data\n",
    "3. Measured performance degradation\n",
    "4. Checked for suspicious patterns\n",
    "\n",
    "NOISE ROBUSTNESS TEST\n",
    "{'-'*80}\n",
    "Baseline (No Noise):\n",
    "  AUC: {baseline_auc:.4f}\n",
    "  F1:  {baseline_f1:.4f}\n",
    "\n",
    "Performance at 10% noise:\n",
    "  AUC: {auc_at_10pct:.4f} (↓ {auc_drop_10:.1f}%)\n",
    "  F1:  {f1_at_10pct:.4f} (↓ {f1_drop_10:.1f}%)\n",
    "\n",
    "Performance at 50% noise:\n",
    "  AUC: {auc_at_50pct:.4f} (↓ {auc_drop_50:.1f}%)\n",
    "  F1:  {f1_at_50pct:.4f} (↓ {f1_drop_50:.1f}%)\n",
    "\n",
    "Performance at 100% noise:\n",
    "  AUC: {auc_at_100pct:.4f} (↓ {((baseline_auc - auc_at_100pct) / baseline_auc * 100):.1f}%)\n",
    "\n",
    "LEAKAGE INDICATORS\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "if leakage_detected:\n",
    "    leakage_report += \"🚨 WARNINGS DETECTED:\\n\"\n",
    "    for warning in warnings:\n",
    "        leakage_report += f\"{warning}\\n\"\n",
    "else:\n",
    "    leakage_report += \"✅ No leakage indicators found\\n\"\n",
    "    leakage_report += \"   Performance degrades appropriately with noise\\n\"\n",
    "\n",
    "leakage_report += f\"\"\"\n",
    "\n",
    "ADDITIONAL TESTS\n",
    "{'-'*80}\n",
    "Identical rows in train/test:  {len(duplicates) if 'duplicates' in locals() else 'N/A'}\n",
    "Overlapping IDs:               {len(overlapping_ids):,} ({100*len(overlapping_ids)/len(test_ids_all):.1f}% of test)\n",
    "\n",
    "VERDICT\n",
    "{'-'*80}\n",
    "\"\"\"\n",
    "\n",
    "if leakage_detected or (len(duplicates) > 0 if 'duplicates' in locals() else False):\n",
    "    leakage_report += \"🚨 POTENTIAL DATA LEAKAGE DETECTED\\n\\n\"\n",
    "    leakage_report += \"RECOMMENDED ACTIONS:\\n\"\n",
    "    leakage_report += \"1. Review data splitting logic\\n\"\n",
    "    leakage_report += \"2. Ensure train/test are split by unique entity IDs\\n\"\n",
    "    leakage_report += \"3. Check feature engineering for temporal leakage\\n\"\n",
    "    leakage_report += \"4. Verify no duplicate pairs across splits\\n\"\n",
    "else:\n",
    "    leakage_report += \"✅ NO DATA LEAKAGE DETECTED\\n\\n\"\n",
    "    leakage_report += \"Model appears to have learned generalizable patterns.\\n\"\n",
    "    leakage_report += \"Performance degrades appropriately with synthetic noise.\\n\"\n",
    "\n",
    "leakage_report += f\"\\n{'='*80}\\n\"\n",
    "\n",
    "# Save report\n",
    "with open(f\"{DATA_DIR}/leakage_test_report.txt\", 'w') as f:\n",
    "    f.write(leakage_report)\n",
    "\n",
    "print(leakage_report)\n",
    "print(f\"✓ Leakage test report saved: {DATA_DIR}/leakage_test_report.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
